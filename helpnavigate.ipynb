{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Project 1 - Surface Type Classification\nxz2830  \nXixi Zhou"},{"metadata":{},"cell_type":"markdown","source":"### Load packages and data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport os\nfor dirname, _, filenames in os.walk('/data'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=pd.read_csv('../input/career-con-2019/X_train.csv')\ny_train=pd.read_csv('../input/career-con-2019/y_train.csv')\nx_test=pd.read_csv('../input/career-con-2019/X_test.csv')\nsub=pd.read_csv('../input/career-con-2019/sample_submission.csv')\n#split X_train\nsamples=20\ntime_series=128\nstart_x = x_train.shape[0] - samples*time_series\nX_train_new, X_test_new = x_train.iloc[:start_x], x_train.iloc[start_x:]\n# split y_train\nstart_y = y_train.shape[0] - samples\ny_train_new, y_test_new = y_train.iloc[:start_y], y_train.iloc[start_y:]\nprint('data loaded')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data exploration\nCheck the train set."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The measurement number is 128 in each series.  \nthere are 3810 series.  \nFeatures in train set seems like normal distribution.  \nThe range of linear_acceleration is large.(max-min)."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train set has no missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check y_train data."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"X_train have entries:\n* Identifiers:row_id,series_id,measurement_number;  \n* Orientation:orientation_x,orientation_y,orientation_z,orientation_w;  \n* angular velocities:angular_velocity_X, angular_velocity_Y, angular_velocity_z;  \n* linear accelerations:linear_acceleration_X,linear_acceleration_Y,linear_acceleration_Z.\ny_train have entries:\n* series_id - is the foreign key reference to X_train.series_id\n* group_id\n* surface"},{"metadata":{},"cell_type":"markdown","source":"Check the value of every kind of surface in y_train set.  \nThere are 9 kinds of surfaces.  \nIt shows that the number of concrete is largest and the number of hard_tiles is smallest.They are uneven distributed.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train['surface'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are also no missing data in y_train."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's sort the target data by group_id.It shows the the distribution is not even either."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,6))\nsns.countplot(x='group_id',data=y_train,order=y_train.group_id.value_counts().index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering\nIn IMU sensor data,there are four coordinates:X,Y,Z,W.    \nIn general,we use X,Y,Z to represent coordinates.But Euler Angles have a limitation called \"gimbal lock\".  \nTo add features, we transform quaternion coordinates to Euler angles."},{"metadata":{"trusted":true},"cell_type":"code","source":"def toEuler(x,y,z,w):\n    t0=2.0*(w*x+y*z)\n    t1=1.0-2.0*(x*x+y*y)\n    Euler_X=math.atan2(t0,t1)\n    \n    t2=2.0*(w*y-z*x)\n    if t2 > +1.0:\n        t2=1.0\n    if t2<-1.0:\n        t2=-1.0\n    Euler_Y=math.asin(t2)\n    \n    t3=(w*z+x*y)*2.0\n    t4=1.0-(y**2+z**2)*2.0\n    Euler_Z=math.atan2(t3,t4)\n    \n    return Euler_X,Euler_Y,Euler_Z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getEulerFeatures(x,y,z,w):\n    xlist,ylist,zlist=[],[],[]\n    for i in range(0,len(x)):\n        E_x,E_y,E_z=toEuler(x[i],y[i],z[i],w[i])\n        xlist.append(E_x)\n        ylist.append(E_y)\n        zlist.append(E_z)\n    return xlist,ylist,zlist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getTotal(x,y,z):\n    total=(x**2+y**x+z**2)**0.5\n    return total","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We add features such as Euler angles and r_angl and angl_euler showing below."},{"metadata":{"trusted":true},"cell_type":"code","source":"def input_data(data):\n    x,y,z,w=data['orientation_X'].tolist(),data['orientation_Y'].tolist(),data['orientation_Z'].tolist(),data['orientation_W'].tolist()\n    xlist,ylist,zlist=getEulerFeatures(x,y,z,w)\n    data['Euler_X']=xlist\n    data['Euler_Y']=ylist\n    data['Euler_Z']=zlist\n    data['total_angl']=getTotal(data['angular_velocity_X'],data['angular_velocity_Y'],data['angular_velocity_Z'])\n    data['total_lin']=getTotal(data['linear_acceleration_X'],data['linear_acceleration_Y'],data['linear_acceleration_Z'])\n    \n    data['total_xyz']=(data['orientation_X']**2+data['orientation_Y']**2+data['orientation_Z']**2)**0.5\n    data['total_euler']=(data['Euler_X']**2+data['Euler_Y']**2+data['Euler_Z']**2)**0.5\n    \n    data['r_angl']=data['total_lin']/data['total_angl'] \n    data['angl_euler']=data['total_angl']/data['total_euler'] \n    return data   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new=input_data(X_train_new)\nX_test_new=input_data(X_test_new)\nx_train=input_data(x_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's merge x_train and y_train to find the relationship between surface and features."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.merge(x_train,y_train,on='series_id')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From figures showing below,the differences between surface is obvious.  \nMost features' distribution are normal distribution.  \nSo in order to improve accuracy,let's add some new features:max,min,range,median,mean,std and etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"features=x_train.columns[3:16]\nsfs=(y_train['surface'].value_counts()).index\nplt.figure(figsize=(15,30))\ni=0\nfor col in features:\n    i+=1\n    plt.subplot(5,3,i)\n    plt.title(col)\n    for surface in sfs:\n        tp=df[df['surface']==surface]\n        sns.kdeplot(tp[col],label=surface)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add features related to normal distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_cal(data):\n    prepd=pd.DataFrame()\n    for col in data.columns:\n        if col in['row_id','series_id','measurement_number']:\n            continue\n        prepd[col+'_max']=data.groupby(['series_id'])[col].max()\n        prepd[col+'_min']=data.groupby(['series_id'])[col].min()\n        prepd[col+'_range']=prepd[col+'_max']-prepd[col+'_min']\n        prepd[col+'_mean']=data.groupby(['series_id'])[col].mean()\n        prepd[col+'_median']=data.groupby(['series_id'])[col].median()\n        prepd[col+'_std']=data.groupby(['series_id'])[col].std()\n        \n    return prepd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new=data_cal(X_train_new)\nX_test_new=data_cal(X_test_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new.head()\n#print(X_train_new.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label Encoding\nAfter featrue engineering,we need to train model.  \nBefore that,let's do label encoding first to transform words in 'surface' to numbers which can be identified."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder=LabelEncoder()\ny_train_new['surface']=encoder.fit_transform(y_train_new['surface'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train_new.shape)\nprint(y_train_new['surface'].shape)\nprint(X_test_new.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We deal with the possible missing data or invalid by using fillna() and replace() functions."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new.fillna(0, inplace = True)\nX_test_new.fillna(0, inplace = True)\n\nX_train_new.replace(-np.inf, 0, inplace = True)\nX_train_new.replace(np.inf, 0, inplace = True)\nX_test_new.replace(-np.inf, 0, inplace = True)\nX_test_new.replace(np.inf, 0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Run Model\nIn this part,I choose two different models:*GBDT* and *Random Forest*.  \nDecision tree is a good model for classification.  \nAnd two model are all combination of decision trees with good quality to predict.But the kernel of two models are different.  \n**Random Forest** is a Bagging method.Each tree will be trained independently by using random sample of data.It is hard to overfit compare to GBDT.  \n**GBDT ** is a Boosting method.New trees help correct errors of previous trained tree.And it is slower than RF.But it may be overfitting because of noisy.  \n\nValidation Strategy: Straitified KFold"},{"metadata":{},"cell_type":"markdown","source":"#### GBDT\nFirst model is GBDT by using GradientBoosting Classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nfolds=StratifiedKFold(n_splits=3,shuffle=True,random_state=5000)\nte=np.zeros((X_test_new.shape[0],9))\ntr=np.zeros((X_train_new.shape[0]))\nscore=0\nfor i, (tr_index,tar_index) in enumerate(folds.split(X_train_new,y_train_new['surface'])):\n    print('fold:',i)\n    Model_train=GradientBoostingClassifier(max_depth=10,n_estimators=50)\n    Model_train.fit(X_train_new.iloc[tr_index],y_train_new['surface'][tr_index])\n    tr[tar_index]=Model_train.predict(X_train_new.iloc[tar_index])   \n    score+=Model_train.score(X_train_new.iloc[tar_index],y_train_new['surface'][tar_index])\n    print('score',Model_train.score(X_train_new.iloc[tar_index],y_train_new['surface'][tar_index]))\nprint('avg_score',score/folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importance=Model_train.feature_importances_\nfeatures=X_train_new.columns\nprint(type(importance))\nplt.figure(figsize=(20,30))\nplt.barh(range(len(importance.tolist())),importance.tolist(),tick_label=features.tolist())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(tr,y_train_new['surface'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RandomForest\nSecond model is RandomForestClassifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfolds=StratifiedKFold(n_splits=5,shuffle=True,random_state=5000)\nte=np.zeros((X_test_new.shape[0],9))\ntr=np.zeros((X_train_new.shape[0]))\nscore=0\nfor i, (tr_index,tar_index) in enumerate(folds.split(X_train_new,y_train_new['surface'])):\n    print('fold:',i)\n    Model_train=RandomForestClassifier(n_estimators=200,n_jobs=-1)\n    Model_train.fit(X_train_new.iloc[tr_index],y_train_new['surface'][tr_index])\n    tr[tar_index]=Model_train.predict(X_train_new.iloc[tar_index])\n    te+=Model_train.predict_proba(X_test_new)/folds.n_splits\n    score+=Model_train.score(X_train_new.iloc[tar_index],y_train_new['surface'][tar_index])\n    print('score',Model_train.score(X_train_new.iloc[tar_index],y_train_new['surface'][tar_index]))\nprint('avg_score',score/folds.n_splits)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importance=Model_train.feature_importances_\nfeatures=X_train_new.columns\nprint(type(importance))\nplt.figure(figsize=(20,30))\nplt.barh(range(len(importance.tolist())),importance.tolist(),tick_label=features.tolist())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tr.shape)\nprint(y_train_new['surface'].shape)\nprint(te.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(tr,y_train_new['surface'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{},"cell_type":"markdown","source":"Obviously,in this problem,RandomForest have higher accuracy and run faster than GBDT."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_new['surface']=encoder.inverse_transform(te.argmax(axis=1))\ny_test_new.to_csv('submission.csv',index=False)\ny_test_new.head(50)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}